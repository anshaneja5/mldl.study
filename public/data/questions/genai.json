{
  "questions": [
    {
      "id": 1,
      "question": "What is Generative AI?",
      "options": [
        "AI that classifies data",
        "AI that creates new data similar to the training data",
        "AI that optimizes existing data",
        "AI that only recognizes patterns"
      ],
      "correctAnswer": 1,
      "explanation": "Generative AI models learn from existing data to create new samples that resemble the training data.",
      "difficulty": "easy"
    },
    {
      "id": 2,
      "question": "Which neural network architecture is commonly used in Generative AI for producing images?",
      "options": [
        "Convolutional Neural Networks (CNN)",
        "Recurrent Neural Networks (RNN)",
        "Generative Adversarial Networks (GANs)",
        "Transformer Networks"
      ],
      "correctAnswer": 2,
      "explanation": "GANs consist of generator and discriminator networks and are widely used for generating realistic images.",
      "difficulty": "medium"
    },
    {
      "id": 3,
      "question": "What is the primary role of the discriminator in a GAN?",
      "options": [
        "Generate fake data",
        "Distinguish real data from fake data",
        "Train the generator",
        "Extract features from data"
      ],
      "correctAnswer": 1,
      "explanation": "The discriminator learns to classify whether data is real or generated by the generator.",
      "difficulty": "medium"
    },
    {
      "id": 4,
      "question": "Which model architecture introduced the attention mechanism extensively used in Generative AI?",
      "options": [
        "CNN",
        "Transformer",
        "RNN",
        "Autoencoder"
      ],
      "correctAnswer": 1,
      "explanation": "Transformer models use self-attention mechanisms improving sequence modeling in Generative AI.",
      "difficulty": "medium"
    },
    {
      "id": 5,
      "question": "In Generative AI, what does 'prompt engineering' refer to?",
      "options": [
        "Training the model",
        "Designing input queries to generate desired responses",
        "Building datasets",
        "Evaluating model performance"
      ],
      "correctAnswer": 1,
      "explanation": "Prompt engineering involves crafting precise input queries to steer model output effectively.",
      "difficulty": "easy"
    },
    {
      "id": 6,
      "question": "Which of the following is NOT a typical application of Generative AI?",
      "options": [
        "Image generation",
        "Text generation",
        "Data encryption",
        "Music composition"
      ],
      "correctAnswer": 2,
      "explanation": "Data encryption is generally outside the scope of Generative AI applications.",
      "difficulty": "easy"
    },
    {
      "id": 7,
      "question": "Which of the following mechanisms is essential in Transformer models in Generative AI?",
      "options": [
        "Backpropagation",
        "Dropout",
        "Self-Attention",
        "Pooling"
      ],
      "correctAnswer": 2,
      "explanation": "Self-attention allows models to weigh the influence of different input tokens effectively.",
      "difficulty": "medium"
    },
    {
      "id": 8,
      "question": "What is 'text-to-image' generation?",
      "options": [
        "Converting text into images using Generative AI models",
        "Labeling images with captions",
        "Translating images to text",
        "Compressing image files"
      ],
      "correctAnswer": 0,
      "explanation": "Text-to-image generation uses textual descriptions to create corresponding images.",
      "difficulty": "easy"
    },
    {
      "id": 9,
      "question": "Which technique is used in Generative AI to prevent a model from overfitting?",
      "options": [
        "Early stopping",
        "Increasing learning rate",
        "Using a larger batch size",
        "Data encryption"
      ],
      "correctAnswer": 0,
      "explanation": "Early stopping stops training when performance on validation data degrades to avoid overfitting.",
      "difficulty": "medium"
    },
    {
      "id": 10,
      "question": "What is the difference between discriminative and generative models?",
      "options": [
        "Discriminative models classify data; generative models generate data samples",
        "Generative models classify data; discriminative models generate data samples",
        "Both generate data samples",
        "Both classify data"
      ],
      "correctAnswer": 0,
      "explanation": "Discriminative models learn decision boundaries, while generative models learn data distributions.",
      "difficulty": "medium"
    },
    {
      "id": 11,
      "question": "Which metric is commonly used to evaluate the quality of generated images in GANs?",
      "options": [
        "Accuracy",
        "Inception Score",
        "Precision",
        "Recall"
      ],
      "correctAnswer": 1,
      "explanation": "Inception Score assesses the quality and diversity of generated images in GANs.",
      "difficulty": "medium"
    },
    {
      "id": 12,
      "question": "What is 'style transfer' in Generative AI?",
      "options": [
        "Converting text to speech",
        "Applying the artistic style of one image to another",
        "Changing the color palette of images",
        "Extracting style features from text"
      ],
      "correctAnswer": 1,
      "explanation": "Style transfer applies the visual style of an image onto the content of another.",
      "difficulty": "medium"
    },
    {
      "id": 13,
      "question": "Which of these is NOT a challenge in Generative AI?",
      "options": [
        "Mode collapse",
        "Training instability",
        "Label scarcity",
        "Overfitting"
      ],
      "correctAnswer": 2,
      "explanation": "Label scarcity is more relevant in supervised learning than generative modeling.",
      "difficulty": "hard"
    },
    {
      "id": 14,
      "question": "Which loss function is typically used to train the discriminator in a GAN?",
      "options": [
        "Mean Squared Error",
        "Binary Cross Entropy",
        "Categorical Cross Entropy",
        "Hinge Loss"
      ],
      "correctAnswer": 1,
      "explanation": "Binary cross-entropy loss helps the discriminator distinguish real vs generated samples.",
      "difficulty": "medium"
    },
    {
      "id": 15,
      "question": "Which one is an example of a transformer-based large language model?",
      "options": [
        "GPT",
        "Autoencoder",
        "CNN",
        "RNN"
      ],
      "correctAnswer": 0,
      "explanation": "GPT (Generative Pretrained Transformer) is a popular transformer-based generative language model.",
      "difficulty": "easy"
    },
    {
      "id": 16,
      "question": "What is the major advantage of transformers over RNNs in sequence modeling?",
      "options": [
        "Parallel processing capability",
        "Higher complexity",
        "Smaller model size",
        "Limited input length"
      ],
      "correctAnswer": 0,
      "explanation": "Transformers enable parallel computation over sequences unlike RNNs which process sequentially.",
      "difficulty": "medium"
    },
    {
      "id": 17,
      "question": "Which Generative AI technique is widely used to generate realistic human voices?",
      "options": [
        "WaveNet",
        "Autoencoders",
        "GAN",
        "Random Forest"
      ],
      "correctAnswer": 0,
      "explanation": "WaveNet is a deep generative model effective in producing human-like speech.",
      "difficulty": "medium"
    },
    {
      "id": 18,
      "question": "What does zero-shot learning refer to in Generative AI?",
      "options": [
        "Training a model with no data",
        "Model generalizing to new tasks without task-specific training",
        "Model forgets previous tasks",
        "Training with random noise"
      ],
      "correctAnswer": 1,
      "explanation": "Zero-shot learning enables models to perform on new tasks unseen during training.",
      "difficulty": "hard"
    },
    {
      "id": 19,
      "question": "In prompt engineering, what is the significance of temperature parameter?",
      "options": [
        "Controls randomness of output generation",
        "Adjusts learning rate",
        "Determines batch size",
        "Defines model depth"
      ],
      "correctAnswer": 0,
      "explanation": "Temperature affects creativity vs determinism in generative model outputs.",
      "difficulty": "medium"
    },
    {
      "id": 20,
      "question": "What does 'fine-tuning' a Generative AI model involve?",
      "options": [
        "Training from scratch",
        "Refining a pre-trained model on a specific dataset",
        "Increasing model size",
        "Deleting old weights"
      ],
      "correctAnswer": 1,
      "explanation": "Fine-tuning adapts a pre-trained model to a new domain or task using new data.",
      "difficulty": "medium"
    },
    {
      "id": 21,
      "question": "What is an autoencoder primarily used for?",
      "options": [
        "Classification",
        "Dimensionality reduction and feature learning",
        "Data generation",
        "Reinforcement learning"
      ],
      "correctAnswer": 1,
      "explanation": "Autoencoders compress and reconstruct data learning compact representations.",
      "difficulty": "medium"
    },
    {
      "id": 22,
      "question": "Which phase involves generating data samples in Generative AI?",
      "options": [
        "Training phase",
        "Inference phase",
        "Validation phase",
        "Test phase"
      ],
      "correctAnswer": 1,
      "explanation": "Inference (generation) phase is when the trained model produces new data.",
      "difficulty": "easy"
    },
    {
      "id": 23,
      "question": "In text generation, what is 'beam search' used for?",
      "options": [
        "Optimizing the model weights",
        "Generating multiple candidate sequences simultaneously",
        "Reducing training time",
        "Encoding input data"
      ],
      "correctAnswer": 1,
      "explanation": "Beam search compares multiple generated sequences to select the most probable.",
      "difficulty": "medium"
    },
    {
      "id": 24,
      "question": "What is the common challenge when evaluating generative models?",
      "options": [
        "Measuring the quality and diversity of generated data",
        "Computational speed",
        "Memory usage",
        "Training data size"
      ],
      "correctAnswer": 0,
      "explanation": "Evaluating both fidelity and diversity of generated data is complex and crucial.",
      "difficulty": "hard"
    },
    {
      "id": 25,
      "question": "What defines the 'latent space' in Generative AI?",
      "options": [
        "The space of model output samples",
        "A compressed feature space representing input data",
        "Raw input data",
        "Model weights"
      ],
      "correctAnswer": 1,
      "explanation": "Latent space captures abstract features in a compact representation used for generation.",
      "difficulty": "medium"
    },
    {
      "id": 26,
      "question": "Which dataset is commonly used to benchmark image generation models?",
      "options": [
        "MNIST",
        "CIFAR-10",
        "ImageNet",
        "COCO"
      ],
      "correctAnswer": 2,
      "explanation": "ImageNet's large set of labeled images is common for training and evaluation.",
      "difficulty": "medium"
    },
    {
      "id": 27,
      "question": "What is 'mode collapse' in GANs?",
      "options": [
        "Generator produces limited variety of outputs",
        "Generator fails to train",
        "Discriminator is too strong",
        "Models learn slowly"
      ],
      "correctAnswer": 0,
      "explanation": "Mode collapse happens when the generator outputs lack diversity and collapse to few modes.",
      "difficulty": "hard"
    },
    {
      "id": 28,
      "question": "Which Generative AI application involves modifying videos to create fake but realistic footage?",
      "options": [
        "Data augmentation",
        "Deepfake technology",
        "Image segmentation",
        "Style transfer"
      ],
      "correctAnswer": 1,
      "explanation": "Deepfake uses Generative AI to create hyper-realistic synthetic audio/video.",
      "difficulty": "medium"
    },
    {
      "id": 29,
      "question": "What role do embeddings play in Generative AI?",
      "options": [
        "Encode data into continuous vector spaces capturing semantic meaning",
        "Generate raw data",
        "Train models faster",
        "Create labels"
      ],
      "correctAnswer": 0,
      "explanation": "Embeddings transform data into numerical vectors that preserve semantic similarities.",
      "difficulty": "medium"
    },
    {
      "id": 30,
      "question": "Which approach allows Generative AI models to learn from smaller datasets by leveraging knowledge from larger datasets?",
      "options": [
        "Pretraining and fine-tuning",
        "Reinforcement learning",
        "K-means clustering",
        "Data cleaning"
      ],
      "correctAnswer": 0,
      "explanation": "Pretraining on large corpora followed by fine-tuning enables efficient learning on smaller datasets.",
      "difficulty": "medium"
    }
  ]
}
