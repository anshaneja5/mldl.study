const researchPapers = {
  "foundational_papers": [
    {
      title: "A Mathematical Theory of Communication",
      url: "https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf"
    },
    {
      title: "A Logical Calculus of the Ideas Immanent in Nervous Activity",
      url: "https://www.cs.cmu.edu/~./epxing/Class/10715/reading/McCulloch.and.Pitts.pdf"
    },
    {
      title: "Intelligent Machinery",
      url: "https://ia801703.us.archive.org/23/items/turing1948/turing1948_text.pdf"
    },
    {
      title: "Programming a Computer for Playing Chess",
      url: "https://archive.computerhistory.org/projects/chess/related_materials/text/2-0%20and%202-1.Programming_a_computer_for_playing_chess.shannon/2-0%20and%202-1.Programming_a_computer_for_playing_chess.shannon.062303002.pdf"
    },
    {
      title: "Perceptron",
      url: "https://bpb-us-e2.wpmucdn.com/websites.umass.edu/dist/a/27637/files/2016/03/rosenblatt-1957.pdf"
    },
    {
      title: "A Symbolic Analysis of Relay and Switching Circuits",
      url: "https://drive.google.com/file/d/1m3JwmCZqWg1IP607I5gbpsJDQBIDwcz9/view"
    }
  ],
  "neural_networks_and_deep_learning": [
    {
      title: "Learning representations by back-propagating errors",
      url: "https://github.com/georgezoto/Convolutional-Neural-Networks/blob/master/Papers/1986%20Backpro%20Learning%20representations%20by%20back-propagating%20errors%20-%20Rumelhart,%20Hinton,%20Williams.pdf"
    },
    {
      title: "Gradient-based learning applied to document recognition",
      url: "https://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf"
    },
    {
      title: "The Annotated Transformer",
      url: "https://nlp.seas.harvard.edu/annotated-transformer/"
    },
    {
      title: "ImageNet Classification with Deep CNNs",
      url: "https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf"
    },
    {
      title: "CS231n Convolutional Neural Networks for Visual Recognition",
      url: "https://cs231n.github.io/"
    },
    {
      title: "Deep Residual Learning for Image Recognition",
      url: "https://arxiv.org/pdf/1512.03385"
    },
    {
      title: "Identity Mappings in Deep Residual Networks",
      url: "https://arxiv.org/pdf/1603.05027"
    },
    {
      title: "Multi-Scale Context Aggregation by Dilated Convolutions",
      url: "https://arxiv.org/pdf/1511.07122"
    }
  ],
  "language_models_and_nlp": [
    {
      title: "Attention Is All You Need",
      url: "https://arxiv.org/pdf/1706.03762"
    },
    {
      title: "Neural Networks and Neural Language Models",
      url: "https://web.stanford.edu/~jurafsky/slp3/7.pdf"
    },
    {
      title: "A Neural Probabilistic Language Model",
      url: "https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf"
    },
    {
      title: "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      url: "https://arxiv.org/pdf/1810.04805"
    },
    {
      title: "The Llama 3 Herd of Models",
      url: "https://arxiv.org/pdf/2407.21783"
    },
    {
      title: "Scaling Laws for Neural LMs",
      url: "https://arxiv.org/pdf/2001.08361"
    }
  ],
  "sequence_models": [
    {
      title: "The Unreasonable Effectiveness of RNNs",
      url: "https://karpathy.github.io/2015/05/21/rnn-effectiveness/"
    },
    {
      title: "Understanding LSTM Networks",
      url: "https://colah.github.io/posts/2015-08-Understanding-LSTMs/"
    },
    {
      title: "Sequence to Sequence Learning with Neural Networks",
      url: "https://arxiv.org/pdf/1409.3215"
    },
    {
      title: "Neural Machine Translation by Jointly Learning to Align and Translate",
      url: "https://arxiv.org/pdf/1409.0473"
    },
    {
      title: "Generating Sequences With Recurrent Neural Networks",
      url: "https://arxiv.org/pdf/1308.0850"
    },
    {
      title: "Recurrent Neural Network Regularization",
      url: "https://arxiv.org/pdf/1409.2329"
    },
    {
      title: "Order Matters: Sequence to sequence for sets",
      url: "https://arxiv.org/pdf/1511.06391"
    },
    {
      title: "Pointer Networks",
      url: "https://arxiv.org/pdf/1506.03134"
    },
    {
      title: "Relational RNNs",
      url: "https://arxiv.org/pdf/1806.01822"
    }
  ],
  "machine_learning_theory": [
    {
      title: "Random Forests",
      url: "https://link.springer.com/content/pdf/10.1023/a:1010933404324.pdf"
    },
    {
      title: "Statistical Modeling: The Two Cultures",
      url: "https://www2.math.uu.se/~thulin/mm/breiman.pdf"
    },
    {
      title: "A Tutorial on Principal Component Analysis",
      url: "https://arxiv.org/pdf/1404.1100"
    },
    {
      title: "An overview of gradient descent optimization algorithms",
      url: "https://arxiv.org/pdf/1609.04747"
    },
    {
      title: "Keeping Neural Networks Simple by Minimizing the Description Length of the Weights",
      url: "https://www.cs.toronto.edu/~hinton/absps/colt93.pdf"
    },
    {
      title: "A Tutorial Introduction to the Minimum Description Length Principle",
      url: "https://arxiv.org/pdf/math/0406077"
    },
    {
      title: "Machine Super Intelligence",
      url: "http://www.vetta.org/documents/Machine_Super_Intelligence.pdf"
    },
    {
      title: "Kolmogorov Complexity and Algorithmic Randomness",
      url: "https://www.lirmm.fr/~ashen/kolmbook-eng-scan.pdf"
    }
  ],
  "memory_and_attention": [
    {
      title: "Memory Networks",
      url: "https://arxiv.org/pdf/1410.3916"
    },
    {
      title: "Neural Turing Machines",
      url: "https://arxiv.org/pdf/1410.5401"
    },
    {
      title: "MemoryBank: Enhancing Large Language Models with Long-Term Memory",
      url: "https://arxiv.org/pdf/2305.10250"
    },
    {
      title: "Effective Approaches to Attention-based Neural Machine Translation",
      url: "https://arxiv.org/pdf/1508.04025"
    }
  ],
  "specialized_applications": [
    {
      title: "Deep Speech 2: End-to-End Speech Recognition in English and Mandarin",
      url: "https://arxiv.org/pdf/1512.02595"
    },
    {
      title: "Self-Driving Cars: A Survey",
      url: "https://arxiv.org/pdf/1901.04407"
    },
    {
      title: "Neural Quantum Chemistry",
      url: "https://arxiv.org/pdf/1704.01212"
    },
    {
      title: "GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism",
      url: "https://arxiv.org/pdf/1811.06965"
    },
    {
      title: "A Simple NN Module for Relational Reasoning",
      url: "https://arxiv.org/pdf/1706.01427"
    }
  ],
  "technical_resources": [
    {
      title: "Papers in 100 Lines of Code",
      url: "https://github.com/MaximeVandegar/Papers-in-100-Lines-of-Code"
    },
    {
      title: "A Mathematical Framework for Transformer Circuits",
      url: "https://transformer-circuits.pub/2021/framework/index.html"
    },
    {
      title: "The NumPy array: a structure for efficient numerical computation",
      url: "https://arxiv.org/pdf/1102.1523"
    }
  ],
  "complexity_and_systems": [
    {
      title: "The First Law of Complexodynamics",
      url: "https://scottaaronson.blog/?p=762"
    },
    {
      title: "Quantifying the Rise and Fall of Complexity in Closed Systems: The Coffee Automaton",
      url: "https://arxiv.org/pdf/1405.6903"
    },
    {
      title: "Variational Lossy Autoencoder",
      url: "https://arxiv.org/pdf/1611.02731"
    }
  ]
};

export default researchPapers;